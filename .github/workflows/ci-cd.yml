name: Python CI/CD

on:
  push:
    branches: [ feature/cicd-pipeline ]
    tags: [ '*' ]
  pull_request:
    branches: [ feature/cicd-pipeline ]

jobs:
  run-test:
    runs-on: ubuntu-latest

    permissions:
      id-token: write
      contents: read
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install uv
        run: pip install uv

      - name: Set up virtual environment
        run: uv venv .venv --python 3.12 --seed

      - name: Activate venv and install dependencies
        working-directory: app/backend
        run: |
          source ../../.venv/bin/activate
          uv pip install -e ".[dev]"

      - name: Login to Azure using OIDC
        uses: azure/login@v1
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Run tests
        working-directory: app/backend
        env:
          AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
          AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
          AZURE_OPENAI_DEPLOYMENT_NAME: ${{ secrets.AZURE_OPENAI_DEPLOYMENT_NAME }}
          AZURE_OPENAI_QUERY_DEPLOYMENT_NAME: ${{ secrets.AZURE_OPENAI_QUERY_DEPLOYMENT_NAME }}
          BING_GROUNDING_PROJECT_ENDPOINT: ${{ secrets.BING_GROUNDING_PROJECT_ENDPOINT }}
          BING_GROUNDING_CONNECTION_ID: ${{ secrets.BING_GROUNDING_CONNECTION_ID }}
          BING_GROUNDING_AGENT_MODEL_DEPLOYMENT_NAME: ${{ secrets.BING_GROUNDING_AGENT_MODEL_DEPLOYMENT_NAME }}
        run: |
          source ../../.venv/bin/activate
          echo "## Pytest result" >> $GITHUB_STEP_SUMMARY

          set +e
          uv run pytest -v tests/ | tee test_output.log
          EXIT_CODE=${PIPESTATUS[0]}
          set -e

          cat test_output.log >> $GITHUB_STEP_SUMMARY

          if grep -qE "tests/test_query_rewriter_integration\.py::test_parametrized_real_query_rewriter\[test_case[01]\] FAILED" test_output.log; then
            echo "⚠️ Known test failures (test_case0 or test_case1) detected"
            echo "ALLOWED_NOTE=\n🟡 *Note*: Allowed failure in test_case0 or test_case1" >> $GITHUB_ENV
            KNOWN_FAILURE=true
          else
            echo "ALLOWED_NOTE=" >> $GITHUB_ENV
            KNOWN_FAILURE=false
          fi

          if [ "$EXIT_CODE" -ne 0 ] && [ "$KNOWN_FAILURE" = false ]; then
            echo "❌ Unhandled test failures occurred"
            exit $EXIT_CODE
          else
            echo "✅ Test status acceptable (either passed or known failures only)"
          fi

      - name: Run batch evaluation
        working-directory: app/backend
        env:
          AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
          AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
          AZURE_OPENAI_DEPLOYMENT_NAME: ${{ secrets.AZURE_OPENAI_DEPLOYMENT_NAME }}
          AZURE_OPENAI_QUERY_DEPLOYMENT_NAME: ${{ secrets.AZURE_OPENAI_QUERY_DEPLOYMENT_NAME }}
          BING_API_KEY: ${{ secrets.BING_API_KEY }}
          BING_GROUNDING_PROJECT_ENDPOINT: ${{ secrets.BING_GROUNDING_PROJECT_ENDPOINT }}
          BING_GROUNDING_CONNECTION_ID: ${{ secrets.BING_GROUNDING_CONNECTION_ID }}
          BING_GROUNDING_AGENT_MODEL_DEPLOYMENT_NAME: ${{ secrets.BING_GROUNDING_AGENT_MODEL_DEPLOYMENT_NAME }}
        run: |
          source ../../.venv/bin/activate
          echo "## Evaluation Results" >> $GITHUB_STEP_SUMMARY
          uv run evals/batch_eval.py \
            --input evals/data/RTF_queries.csv \
            --max_concurrent 3 \
            --max_tokens 1500 \
            --temperature 0.5 \
            --query_rewrite true \
            --plan_execute true \
            --search_engine grounding_bing

      - name: Parse evaluation results and add to summary
        working-directory: app/backend
        if: always()
        id: eval_results
        run: |
          if [ -f evals/results/evaluation_results_*.json ]; then
            LATEST_RESULT=$(ls -t evals/results/evaluation_results_*.json | head -1)
            echo "Found evaluation result: $LATEST_RESULT"

          RELEVANCE_SCORE=$(python3 -c "
          import json
          import sys
          try:
              with open('$LATEST_RESULT', 'r', encoding='utf-8') as f:
                  data = json.load(f)
              score = data.get('metrics', {}).get('relevance.relevance', 0)
              print(f'{score:.1f}')
          except Exception as e:
              print('0.0')
              sys.stderr.write(f'Error parsing relevance score: {e}\n')
            " 2>/dev/null || echo "0.0")

          PASS_RATE=$(python3 -c "
          import json
          import sys
          try:
              with open('$LATEST_RESULT', 'r', encoding='utf-8') as f:
                  data = json.load(f)
              rows = data.get('rows', [])
              total = len(rows)
              if total > 0:
                  passed = sum(1 for row in rows if row.get('outputs.relevance.relevance_result') == 'pass')
                  print(f'{passed}/{total} ({passed/total*100:.1f}%)')
              else:
                  print('0/0 (0.0%)')
          except Exception as e:
              print('0/0 (0.0%)')
              sys.stderr.write(f'Error parsing pass rate: {e}\n')
            " 2>/dev/null || echo "0/0 (0.0%)")

            echo "relevance_score=$RELEVANCE_SCORE" >> $GITHUB_OUTPUT
            echo "pass_rate=$PASS_RATE" >> $GITHUB_OUTPUT

            echo "### 📊 Evaluation Results" >> $GITHUB_STEP_SUMMARY
            echo "- **Relevance Score**: $RELEVANCE_SCORE/5.0" >> $GITHUB_STEP_SUMMARY
            echo "- **Pass Rate**: $PASS_RATE" >> $GITHUB_STEP_SUMMARY
            echo "- **Result File**: $(basename $LATEST_RESULT)" >> $GITHUB_STEP_SUMMARY
          else
            echo "No evaluation results found"
            echo "relevance_score=0.0" >> $GITHUB_OUTPUT
            echo "pass_rate=0/0 (0.0%)" >> $GITHUB_OUTPUT
            echo "### ⚠️ No Evaluation Results Found" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Rename files for artifact upload
        working-directory: app/backend
        if: always()
        run: |
          if [ -d evals/results ]; then
            cd evals/results
            for file in *:*; do
              if [ -f "$file" ]; then
                new_name=$(echo "$file" | sed 's/:/-/g')
                echo "Renaming: $file -> $new_name"
                mv "$file" "$new_name"
              fi
            done
          else
            echo "No results directory found. Skipping renaming step."
          fi

      - name: Upload evaluation artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: evaluation-results-${{ github.sha }}
          path: |
            app/backend/evals/results/*.json
            app/backend/evals/results/*.jsonl
            app/backend/evals/results/*.html
          retention-days: 7

      - name: Notify Slack on test success
        if: success()
        run: |
          RELEVANCE_SCORE="${{ steps.eval_results.outputs.relevance_score }}"
          PASS_RATE="${{ steps.eval_results.outputs.pass_rate }}"
          BRANCH_REF="${{ github.ref }}"
          COMMIT_SHA="${{ github.sha }}"
          if grep -qE "tests/test_query_rewriter_integration\.py::test_parametrized_real_query_rewriter\[test_case[01]\] FAILED" app/backend/test_output.log; then
            ALLOWED_NOTE="🟡 *Note*: Allowed failure in test_case0 or test_case1"
          else
            ALLOWED_NOTE=""
          fi

          curl -X POST -H 'Content-type: application/json' \
               --data "{\"text\":\"🟢 *Test & Evaluation Passed*\\n📊 Relevance: ${RELEVANCE_SCORE}/5.0\\n✅ Pass Rate: ${PASS_RATE}\\nBranch: ${BRANCH_REF}\\nCommit: ${COMMIT_SHA}\\n${ALLOWED_NOTE}\"}" \
               ${{ secrets.SLACK_WEBHOOK_URL }}

      - name: Notify Slack on test failure
        if: failure()
        run: |
          BRANCH_REF="${{ github.ref }}"
          COMMIT_SHA="${{ github.sha }}"

          curl -X POST -H 'Content-type: application/json' \
               --data "{\"text\":\"🔴 *Test or Evaluation Failed*\\nBranch: ${BRANCH_REF}\\nCommit: ${COMMIT_SHA}\"}" \
               ${{ secrets.SLACK_WEBHOOK_URL }}

  deploy:
    needs: run-test
    runs-on: ubuntu-latest
    if: startsWith(github.ref, 'refs/tags/')
    environment: production

    permissions:
      id-token: write
      contents: read

    env:
      RG_NAME: plan-search-rg
      ACR_NAME: ${{ secrets.ACR_NAME }}
      IMAGE_TAG: ${{ github.ref_name }}
      BACKEND_IMG: ${{ secrets.ACR_NAME }}.azurecr.io/plan-search-be:${{ github.ref_name }}
      FRONTEND_IMG: ${{ secrets.ACR_NAME }}.azurecr.io/plan-search-fe:${{ github.ref_name }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Login to Azure using OIDC
        uses: azure/login@v1
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Create backend-env.json from plain secret
        run: echo '${{ secrets.BACKEND_ENV_JSON }}' > infra/backend-env.json

      - name: Create main.parameters.json from plain secret
        run: echo '${{ secrets.MAIN_PARAMETERS_JSON }}' > infra/main.parameters.json

      - name: Build and push backend image
        run: |
          az acr build --registry ${{ env.ACR_NAME }} \
                      --image    ${{ env.BACKEND_IMG }} \
                      ./app/backend

      - name: Build and push frontend image
        run: |
          az acr build --registry ${{ env.ACR_NAME }} \
                      --image    ${{ env.FRONTEND_IMG }} \
                      ./app/frontend

      - name: Deploy Bicep template
        run: |
          az deployment group create \
            --resource-group  ${{ env.RG_NAME }} \
            --name            plan-search-deployment-${{ github.run_id }} \
            --template-file   infra/main.bicep \
            --parameters      @infra/main.parameters.json \
                              backendContainerImage=${{ env.BACKEND_IMG }} \
                              frontendContainerImage=${{ env.FRONTEND_IMG }} \
                              acrName=${{ env.ACR_NAME }} \
            --no-prompt \
            --debug 2>&1 | tee deployment.log

      - name: Notify Slack on CD success
        if: success()
        run: |
          curl -X POST -H 'Content-type: application/json' \
               --data '{"text":"📦 *CD Success*\nBranch: '${{ github.ref }}'\nCommit: '${{ github.sha }}'"}' \
               ${{ secrets.SLACK_WEBHOOK_URL }}

      - name: Notify Slack on CD failure
        if: failure()
        run: |
          curl -X POST -H 'Content-type: application/json' \
               --data '{"text":"⚠️ *CD Failed*\nBranch: '${{ github.ref }}'\nCommit: '${{ github.sha }}'"}' \
               ${{ secrets.SLACK_WEBHOOK_URL }}